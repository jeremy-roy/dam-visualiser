{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b834e-b864-4744-ba5c-0be9d77c9877",
   "metadata": {},
   "source": [
    "# Western Cape Dam Levels\n",
    "Data has been downloaded from City of Cape Town Open Data Portal:  \n",
    "\n",
    "## GIS\n",
    "City of Cape Town Corporate GIS  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::bulk-water-dams-1/explore?location=-33.865920%2C19.071866%2C11.86  \n",
    "<br>\n",
    "Bulk Water dams (Bulk_Water_Dams.geojson):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::bulk-water-dams-1/explore?location=-33.865920%2C19.071866%2C11.86  \n",
    "<br>\n",
    "## Timeseries\n",
    "Dam Levels (Dam_Levels_from_2012.csv):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::dam-levels-from-2012/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Water Consumption (data/Water_consumption.xlsx):  \n",
    "https://odp-cctegis.opendata.arcgis.com/documents/cctegis::water-consumption-1/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Inland Water Quality Monthly Summary Report (Inland_WQ_Summary_Report.pdf):  \n",
    "https://odp-cctegis.opendata.arcgis.com/documents/cctegis::inland-water-quality-monthly-summary-report/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Rainfall Data From 2000 (Rainfall_Data_2000_to_2024.csv):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::rainfall-data-from-2000-1/explore  \n",
    "\n",
    "## Weather Data\n",
    "meteostat python package \n",
    "\n",
    "## Poulations data\n",
    "https://www.macrotrends.net/global-metrics/cities/22481/cape-town/population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38fba9f-02a6-4d34-a3df-f0b1d7869532",
   "metadata": {},
   "source": [
    "### STEP 1: Dam Levels Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b062ec-61a2-4d69-ac6e-f35d39652719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/wxbydyks55v97c1svmphzx_80000gn/T/ipykernel_20922/547504456.py:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['DATE'] = pd.to_datetime(df['DATE'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load dam polygon GeoJSON\n",
    "gdf = gpd.read_file(\"data/2025-05-01/Bulk_Water_Dams.geojson\")\n",
    "\n",
    "# Load dam levels CSV\n",
    "df = pd.read_csv(\"data/2025-05-19/Dam_Levels_from_2012.csv\", encoding=\"ISO-8859-1\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(r\"\\s+\", \"\", regex=True).str.lower()\n",
    "\n",
    "# Mapping from NAME in GeoJSON to CSV prefix (lowercase, no spaces)\n",
    "dam_name_mapping = {\n",
    "    \"Woodhead\": \"woodhead\",\n",
    "    \"Hely-Hutchinson\": \"hely-hutchinson\",\n",
    "    \"Lewis Gay\": \"lewisgay\",\n",
    "    \"Kleinplaats\": \"kleinplaats\",\n",
    "    \"Victoria\": \"victoria\",\n",
    "    \"Alexandra\": \"alexandra\",\n",
    "    \"De Villiers\": \"devilliers\",\n",
    "    \"Steenbras Lower\": \"steenbraslower\",\n",
    "    \"Steenbras Upper\": \"steenbrasupper\",\n",
    "    \"Voëlvlei\": \"voëlvlei\",\n",
    "    \"Wemmershoek\": \"wemmershoek\",\n",
    "    \"Theewaterskloof\": \"theewaterskloof\",\n",
    "    \"Berg River\": \"bergriver\",\n",
    "    \"Land-en-Zeezicht Dam\": \"land-enzeezicht\",\n",
    "    \"Big 5 Total\": \"totalstored-big5\",\n",
    "    \"Big 6 Total\": \"totalstored-big6\"\n",
    "}\n",
    "\n",
    "def build_timeseries(prefix):\n",
    "    # Find all columns related to this dam (that start with the prefix)\n",
    "    prefix_cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "\n",
    "    def find_col(keyword):\n",
    "        # Look for a column that contains the keyword (case-insensitive)\n",
    "        matches = [col for col in prefix_cols if keyword in col]\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    # Find matching columns\n",
    "    height_col = find_col(\"height\")\n",
    "    storage_col = find_col(\"storage\")\n",
    "    current_col = find_col(\"current\")\n",
    "    last_year_col = find_col(\"lastyear\")\n",
    "\n",
    "    # If we find no relevant columns, return empty\n",
    "    if not any([height_col, storage_col, current_col, last_year_col]):\n",
    "        return [], None\n",
    "\n",
    "    # Build DataFrame\n",
    "    cols = {'date': 'date'}\n",
    "    if height_col: cols[height_col] = 'height_m'\n",
    "    if storage_col: cols[storage_col] = 'storage_ml'\n",
    "    if current_col: cols[current_col] = 'percent_full'\n",
    "    if last_year_col: cols[last_year_col] = 'last_year_percent_full'\n",
    "\n",
    "    col_keys = list(cols.keys())\n",
    "    if 'date' not in col_keys:\n",
    "        col_keys = ['date'] + col_keys\n",
    "    ts = df[col_keys].copy()\n",
    "    ts['date'] = pd.to_datetime(ts['date']).dt.strftime('%Y-%m-%d')  # ensure datetime\n",
    "    ts.rename(columns=cols, inplace=True)\n",
    "\n",
    "    # format nulls\n",
    "    ts = ts.where(pd.notnull(ts), None)\n",
    "\n",
    "    # Get the latest dam level value\n",
    "    current = ts.dropna(subset=['percent_full']) if 'percent_full' in ts.columns else ts\n",
    "    current_percentage_full = current.sort_values(\"date\").iloc[-1][\"percent_full\"] if not current.empty and 'percent_full' in current.columns else None\n",
    "\n",
    "    return ts.to_dict(orient=\"records\"), current_percentage_full\n",
    "\n",
    "\n",
    "# Create output containers\n",
    "dam_ts_daily = {}\n",
    "dam_ts_monthly = {}\n",
    "dam_ts_yearly = {}\n",
    "\n",
    "for dam_name, prefix in dam_name_mapping.items():\n",
    "    ts, _ = build_timeseries(prefix)\n",
    "    if not ts:\n",
    "        continue\n",
    "\n",
    "    df_ts = pd.DataFrame(ts)\n",
    "    df_ts['date'] = pd.to_datetime(df_ts['date'])\n",
    "\n",
    "    # DAILY\n",
    "    df_ts_sorted = df_ts.sort_values('date')\n",
    "    df_ts_sorted['date'] = df_ts_sorted['date'].dt.strftime('%Y-%m-%d')\n",
    "    dam_ts_daily[prefix] = df_ts_sorted.where(pd.notnull(df_ts_sorted), None).to_dict(orient='records')\n",
    "\n",
    "    # MONTHLY\n",
    "    monthly = df_ts.resample('ME', on='date').mean(numeric_only=True).reset_index()\n",
    "    monthly['date'] = monthly['date'].dt.strftime('%Y-%m')\n",
    "    dam_ts_monthly[prefix] = monthly.where(pd.notnull(monthly), None).to_dict(orient='records')\n",
    "\n",
    "    # YEARLY\n",
    "    yearly = df_ts.resample('YE', on='date').mean(numeric_only=True).reset_index()\n",
    "    yearly['date'] = yearly['date'].dt.strftime('%Y')\n",
    "    dam_ts_yearly[prefix] = yearly.where(pd.notnull(yearly), None).to_dict(orient='records')\n",
    "\n",
    "\n",
    "# Update GeoJSON properties with current_percentage_full and current_date\n",
    "for i, row in gdf.iterrows():\n",
    "    dam_name = row[\"NAME\"]\n",
    "    prefix = dam_name_mapping.get(dam_name)\n",
    "    if not prefix:\n",
    "        continue\n",
    "\n",
    "    ts, _ = build_timeseries(prefix)\n",
    "    if not ts:\n",
    "        continue\n",
    "\n",
    "    df_ts = pd.DataFrame(ts)\n",
    "    df_ts['date'] = pd.to_datetime(df_ts['date'])\n",
    "    current = df_ts.dropna(subset=['percent_full']) if 'percent_full' in df_ts.columns else df_ts\n",
    "\n",
    "    if not current.empty and 'percent_full' in current.columns:\n",
    "        current_pct = current.sort_values(\"date\").iloc[-1]['percent_full']\n",
    "        current_date = current.sort_values(\"date\").iloc[-1]['date'].strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        current_pct = None\n",
    "        current_date = None\n",
    "\n",
    "    gdf.at[i, 'current_percentage_full'] = current_pct\n",
    "    gdf.at[i, 'current_date'] = current_date\n",
    "\n",
    "# Clean NaNs recursively\n",
    "def clean_nans(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_nans(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_nans(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (np.isnan(v := obj)):\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "# Save Timeseries data\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/dam_levels_daily.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(dam_ts_daily), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/dam_levels_monthly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(dam_ts_monthly), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/dam_levels_yearly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(dam_ts_yearly), f, indent=2)\n",
    "\n",
    "# Save enriched GeoJSON\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "gdf.to_file(\"output/Bulk_Water_Dams_Enriched.geojson\", driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282339e-12cd-469f-88ee-e4322c1f85da",
   "metadata": {},
   "source": [
    "### STEP 2: Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419c3005-73ba-4505-b022-13809028c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_nans(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_nans(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_nans(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (np.isnan(v := obj)):\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "\n",
    "# Define Cape Town coordinates\n",
    "cape_town = Point(-33.9258, 18.4232)\n",
    "\n",
    "# Time range: last 20 years\n",
    "start = datetime(2000, 1, 1)\n",
    "end = datetime(2025, 5, 18)\n",
    "\n",
    "# Fetch daily weather data\n",
    "data = Daily(cape_town, start, end)\n",
    "data = data.fetch()\n",
    "\n",
    "# Filter for average temperature and precipitation\n",
    "df = data[['tavg', 'prcp']].copy()\n",
    "\n",
    "# resample monthly\n",
    "monthly = df.resample('ME').mean()\n",
    "monthly['prcp'] = df['prcp'].resample('ME').sum()\n",
    "\n",
    "# resample yearly\n",
    "yearly = df.resample('YE').mean()\n",
    "yearly['prcp'] = df['prcp'].resample('YE').sum()\n",
    "\n",
    "# Add date columns for export\n",
    "df = df.copy()\n",
    "df = df.sort_index()\n",
    "df['date'] = df.index.strftime('%Y-%m-%d')\n",
    "daily_out = df.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "monthly = monthly.copy()\n",
    "monthly['date'] = monthly.index.strftime('%Y-%m')\n",
    "monthly_out = monthly.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "yearly = yearly.copy()\n",
    "yearly['date'] = yearly.index.strftime('%Y')\n",
    "yearly_out = yearly.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_daily.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(daily_out.to_dict(orient='records')), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_monthly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(monthly_out.to_dict(orient='records')), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_yearly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(yearly_out.to_dict(orient='records')), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdd511-7dbe-4b5f-b9bb-9b09a90855cd",
   "metadata": {},
   "source": [
    "### STEP 3: Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b0494ec-8469-47fd-9295-69aa7479419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'Population']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8f1323-db5e-42b2-8fd8-5460f0ba26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "annualPpopulationData = 'data/2025-05-19/Cape-Town-Population-Total-Population-By-Year-2025-05-17-22-32.csv'\n",
    "\n",
    "# Load dam levels CSV\n",
    "df = pd.read_csv(annualPpopulationData)\n",
    "df.rename(columns={'Unnamed: 0': 'year'}, inplace=True)\n",
    "# df['year'] = pd.to_datetime(df['year'])\n",
    "df.columns = ['year', 'population']\n",
    "\n",
    "df = df[['year', 'population']].dropna().sort_values('year')\n",
    "\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_population_yearly.json\", \"w\") as f:\n",
    "    json.dump(df.to_dict(orient='records'), f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
