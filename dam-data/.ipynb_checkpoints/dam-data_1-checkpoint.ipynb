{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91160355-e3f3-4f71-82c5-4accb2ec700a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'WEMMERSHOEK HEIGHT(m)', 'WEMMERSHOEK STORAGE(Ml)',\n",
       "       'WEMMERSHOEK Current%', 'WEMMERSHOEK Last Year%',\n",
       "       'STEENBRAS LOWER HEIGHT(m)', 'STEENBRAS STORAGE (Ml)',\n",
       "       'STEENBRAS LOWER Current %', 'STEENBRAS LOWER Last Year %',\n",
       "       'STEENBRAS UPPER HEIGHT(m)', 'STEENBRAS UPPER STORAGE(Ml)',\n",
       "       'STEENBRAS UPPER Current %', 'STEENBRAS UPPERLast Year %',\n",
       "       'VOﾃ記VLEI HEIGHT (m)', 'VOﾃ記VLEI STORAGE (Ml)', 'VOﾃ記VLEI  Current %',\n",
       "       'VOﾃ記VLEI Last Year% ', 'HELY-HUTCHINSON HEIGHT(m)',\n",
       "       'HELY-HUTCHINSON STORAGE (Ml)', 'HELY-HUTCHINSON Current %',\n",
       "       'HELY-HUTCHINSON Last Year%', 'WOODHEAD HEIGHT', 'WOODHEAD STORAGE(Ml)',\n",
       "       'WOODHEAD Current%', 'WOODHEAD Last Year%', 'VICTORIA HEIGHT',\n",
       "       'VICTORIA STORAGE(Ml)', 'VICTORIA Current%', 'VICTORIALast Year%',\n",
       "       'ALEXANDRA HEIGHT(m)', 'ALEXANDRA STORAGE(Ml)', 'ALEXANDRA Current%',\n",
       "       'ALEXANDRA Last Year%', 'DE VILLIERS HEIGHT(m)',\n",
       "       'DE VILLIERS STORAGE(Ml)', 'DE VILLIERS Current%',\n",
       "       'DE VILLIERS Last Year%', 'KLEINPLAATS HEIGHT (m)',\n",
       "       'KLEINPLAATS STORAGE(Ml)', 'KLEINPLAATS Current %',\n",
       "       'KLEINPLAATS Last Year %', 'LEWIS GAY HEIGHT (m)',\n",
       "       'LEWIS GAY STORAGE (Ml)', 'LEWIS GAY Current %',\n",
       "       'LEWIS GAY Last Year %', 'THEEWATERSKLOOF HEIGHT (m)',\n",
       "       'THEEWATERSKLOOF STORAGE (Ml)', 'THEEWATERSKLOOF Current',\n",
       "       'THEEWATERSKLOOF Last Year %', 'BERG RIVER HEIGHT (m)',\n",
       "       'BERG RIVER STORAGE (Ml)', 'BERG RIVER Current %',\n",
       "       'BERG RIVER Last Year %', 'TOTAL STORED - BIG 6 STORAGE',\n",
       "       'TOTAL STORED - BIG 6 Current', 'TOTAL STORED - BIG 6 Last Year',\n",
       "       'LAND-en ZEEZICHT HEIGHT (m)', 'LAND-en ZEEZICHT STORAGE (Ml)',\n",
       "       'LAND-en ZEEZICHT Current %', 'LAND-en ZEEZICHT Last Year %',\n",
       "       'TOTAL STORED - BIG 5 STORAGE', 'TOTAL STORED - BIG 5 Current',\n",
       "       'TOTAL STORED - BIG 5 Last Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load data ---\n",
    "df = pd.read_csv(\"data/Dam_Levels_from_2012.csv\", encoding=\"ISO-8859-1\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2661ecc-0dfa-4fb1-8f9f-abdd666934a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d21a2636-dc40-4185-9574-342b8054b60b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/wxbydyks55v97c1svmphzx_80000gn/T/ipykernel_14275/3307496591.py:34: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['DATE'] = pd.to_datetime(df['DATE'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['TOTAL STORED - BIG 6 HEIGHT'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m last_year_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Last Year%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Last Year%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Last Year %\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Last Year %\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Last Year\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Last Year\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mLast Year %\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mLast Year %\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mLast Year%\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Extract timeseries\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDATE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_year_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     78\u001b[0m ts\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight_m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstorage_ml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpercent_full\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_year_percent_full\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     79\u001b[0m ts\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpercent_full\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['TOTAL STORED - BIG 6 HEIGHT'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pandas._libs.tslibs.nattype import NaTType\n",
    "\n",
    "# --- Load data ---\n",
    "gdf = gpd.read_file(\"data/Bulk_Water_Dams.geojson\")\n",
    "\n",
    "# Add Total storage rows\n",
    "new_rows = [\n",
    "    {\n",
    "        \"NAME\": \"Big 6 Total\",\n",
    "        \"CPCT\": None,\n",
    "        \"geometry\": None\n",
    "    },\n",
    "    {\n",
    "        \"NAME\": \"Big 5 Total\",\n",
    "        \"CPCT\": None,\n",
    "        \"geometry\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "new_gdf = gpd.GeoDataFrame(new_rows, geometry=\"geometry\", crs=gdf.crs)\n",
    "\n",
    "# Append to original GeoDataFrame\n",
    "gdf = pd.concat([gdf, new_gdf], ignore_index=True)\n",
    "\n",
    "df = pd.read_csv(\"data/Dam_Levels_from_2012.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# --- Clean date column ---\n",
    "# df['DATE'] = pd.to_datetime(df['DATE'], format='%Y-%m-%d', errors='coerce')\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# Remove ALL whitespace from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns = df.columns.str.replace(\"  \", \" \", regex=True)\n",
    "\n",
    "# --- Prepare mapping between GeoJSON NAME and CSV column prefix ---\n",
    "dam_name_mapping = {\n",
    "    \"Woodhead\": \"WOODHEAD\",\n",
    "    \"Hely-Hutchinson\": \"HELY-HUTCHINSON\",\n",
    "    \"Lewis Gay\": \"LEWIS GAY\",\n",
    "    \"Kleinplaats\": \"KLEINPLAATS\",\n",
    "    \"Victoria\": \"VICTORIA\",\n",
    "    \"Alexandra\": \"ALEXANDRA\",\n",
    "    \"De Villiers\": \"DE VILLIERS\",\n",
    "    \"Steenbras Lower\": \"STEENBRAS LOWER\",\n",
    "    \"Steenbras Upper\": \"STEENBRAS UPPER\",\n",
    "    \"Voﾃｫlvlei\": \"VOﾃ記VLEI\",\n",
    "    \"Wemmershoek\": \"WEMMERSHOEK\",\n",
    "    \"Theewaterskloof\": \"THEEWATERSKLOOF\",\n",
    "    \"Berg River\": \"BERG RIVER\",\n",
    "    \"Land-en-Zeezicht Dam\": \"LAND-en ZEEZICHT\",\n",
    "    \"Big 6 Total\": \"TOTAL STORED - BIG 6\",\n",
    "    \"Big 5 Total\": \"TOTAL STORED - BIG 5\"\n",
    "}\n",
    "\n",
    "# --- Build output features ---\n",
    "features = []\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    dam_name = row[\"NAME\"]\n",
    "    csv_key = dam_name_mapping.get(dam_name)\n",
    "\n",
    "    if not csv_key:\n",
    "        continue  # Skip dams not found in CSV mapping\n",
    "\n",
    "    # Define expected columns\n",
    "    height_col = f\"{csv_key} HEIGHT(m)\" if f\"{csv_key} HEIGHT(m)\" in df.columns else f\"{csv_key} HEIGHT (m)\" if f\"{csv_key} HEIGHT (m)\" in df.columns else f\"{csv_key} HEIGHT\"\n",
    "    storage_col = f\"{csv_key} STORAGE(Ml)\" if f\"{csv_key} STORAGE(Ml)\" in df.columns else f\"{csv_key} STORAGE (Ml)\" if f\"{csv_key} STORAGE (Ml)\" in df.columns else f\"{csv_key} STORAGE\" if f\"{csv_key} STORAGE\" in df.columns else \"STEENBRAS STORAGE (Ml)\"\n",
    "    current_col = f\"{csv_key} Current%\" if f\"{csv_key} Current%\" in df.columns else f\"{csv_key} Current %\" if f\"{csv_key} Current %\" in df.columns else f\"{csv_key} Current\"\n",
    "    last_year_col = f\"{csv_key} Last Year%\" if f\"{csv_key} Last Year%\" in df.columns else f\"{csv_key} Last Year %\" if f\"{csv_key} Last Year %\" in df.columns else f\"{csv_key} Last Year\" if f\"{csv_key} Last Year\" in df.columns else f\"{csv_key}Last Year %\" if f\"{csv_key}Last Year %\" in df.columns else f\"{csv_key}Last Year%\"\n",
    "\n",
    "    # Extract timeseries\n",
    "    ts = df[['DATE', height_col, storage_col, current_col, last_year_col]].copy()\n",
    "    ts.columns = ['date', 'height_m', 'storage_ml', 'percent_full', 'last_year_percent_full']\n",
    "    ts.dropna(subset=['percent_full'], inplace=True)\n",
    "\n",
    "    # Format timeseries for output\n",
    "    ts['date'] = ts['date'].dt.strftime('%Y-%m-%d')  # Convert Timestamps to ISO strings\n",
    "    ts = ts.where(pd.notnull(ts), None)  # Replace all NaNs with None\n",
    "    timeseries = ts.to_dict(orient='records')\n",
    "\n",
    "    # Get most recent percent full\n",
    "    current_percentage_full = ts.sort_values(\"date\").iloc[-1][\"percent_full\"]\n",
    "\n",
    "    # Calculate centroid\n",
    "    \n",
    "\n",
    "    # Build feature\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": row[\"geometry\"].__geo_interface__,\n",
    "        \"properties\": {\n",
    "            k: (\n",
    "                v.strftime('%Y-%m-%dT%H:%M:%SZ') if isinstance(v, pd.Timestamp)\n",
    "                else None if isinstance(v, NaTType)\n",
    "                else v\n",
    "            )\n",
    "            for k, v in row.drop(\"geometry\").items()\n",
    "        }\n",
    "    }\n",
    "    # add centroid...\n",
    "    feature[\"properties\"][\"current_percentage_full\"] = current_percentage_full\n",
    "    feature[\"properties\"][\"timeseries\"] = timeseries\n",
    "\n",
    "    features.append(feature)\n",
    "\n",
    "\n",
    "\n",
    "# --- Build final GeoJSON ---\n",
    "output_geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"name\": \"SL_WTNK_BULK_DAMS_SYNC\",\n",
    "    \"crs\": {\n",
    "        \"type\": \"name\",\n",
    "        \"properties\": {\"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\"}\n",
    "    },\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# --- Save to file ---\n",
    "# with open(\"output/Bulk_Water_Dams_Enriched.geojson\", \"w\") as f:\n",
    "#     json.dump(output_geojson, f)\n",
    "\n",
    "output_geojson.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e518b79-a66b-4668-8082-d0af78d21441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
