{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b834e-b864-4744-ba5c-0be9d77c9877",
   "metadata": {},
   "source": [
    "# Western Cape Dam Levels\n",
    "Data has been downloaded from City of Cape Town Open Data Portal:  \n",
    "\n",
    "## GIS\n",
    "City of Cape Town Corporate GIS  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::bulk-water-dams-1/explore?location=-33.865920%2C19.071866%2C11.86  \n",
    "<br>\n",
    "Bulk Water dams (Bulk_Water_Dams.geojson):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::bulk-water-dams-1/explore?location=-33.865920%2C19.071866%2C11.86  \n",
    "<br>\n",
    "## Timeseries\n",
    "Dam Levels (Dam_Levels_from_2012.csv):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::dam-levels-from-2012/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Water Consumption (data/Water_consumption.xlsx):  \n",
    "https://odp-cctegis.opendata.arcgis.com/documents/cctegis::water-consumption-1/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Inland Water Quality Monthly Summary Report (Inland_WQ_Summary_Report.pdf):  \n",
    "https://odp-cctegis.opendata.arcgis.com/documents/cctegis::inland-water-quality-monthly-summary-report/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Rainfall Data From 2000 (Rainfall_Data_2000_to_2024.csv):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::rainfall-data-from-2000-1/explore  \n",
    "\n",
    "## Weather Data\n",
    "meteostat python package \n",
    "\n",
    "## Poulations data\n",
    "https://www.macrotrends.net/global-metrics/cities/22481/cape-town/population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38fba9f-02a6-4d34-a3df-f0b1d7869532",
   "metadata": {},
   "source": [
    "### STEP 1: Dam Levels Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b062ec-61a2-4d69-ac6e-f35d39652719",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l4/wxbydyks55v97c1svmphzx_80000gn/T/ipykernel_66119/742179657.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load dam polygon GeoJSON\n",
    "gdf = gpd.read_file(\"data/2025-05-01/Bulk_Water_Dams.geojson\")\n",
    "\n",
    "# Load dam levels CSV, set date format\n",
    "df = pd.read_csv(\"data/2025-05-28/Dam_Levels_from_2012.csv\", encoding=\"ISO-8859-1\")\n",
    "df['DATE'] = df['DATE'].str.replace('Sept', 'Sep', regex=False)\n",
    "df['DATE'] = pd.to_datetime(df['DATE'], format='%d-%b-%y')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(r\"\\s+\", \"\", regex=True).str.lower()\n",
    "\n",
    "# Mapping from NAME in GeoJSON to CSV prefix (lowercase, no spaces)\n",
    "dam_name_mapping = {\n",
    "    \"Woodhead\": \"woodhead\",\n",
    "    \"Hely-Hutchinson\": \"hely-hutchinson\",\n",
    "    \"Lewis Gay\": \"lewisgay\",\n",
    "    \"Kleinplaats\": \"kleinplaats\",\n",
    "    \"Victoria\": \"victoria\",\n",
    "    \"Alexandra\": \"alexandra\",\n",
    "    \"De Villiers\": \"devilliers\",\n",
    "    \"Steenbras Lower\": \"steenbraslower\",\n",
    "    \"Steenbras Upper\": \"steenbrasupper\",\n",
    "    \"Voëlvlei\": \"voëlvlei\",\n",
    "    \"Wemmershoek\": \"wemmershoek\",\n",
    "    \"Theewaterskloof\": \"theewaterskloof\",\n",
    "    \"Berg River\": \"bergriver\",\n",
    "    \"Land-en-Zeezicht Dam\": \"land-enzeezicht\",\n",
    "    \"Big 5 Total\": \"totalstored-big5\",\n",
    "    \"Big 6 Total\": \"totalstored-big6\"\n",
    "}\n",
    "\n",
    "def build_timeseries(prefix):\n",
    "    # Find all columns related to this dam (that start with the prefix)\n",
    "    prefix_cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "\n",
    "    def find_col(keyword):\n",
    "        # Look for a column that contains the keyword (case-insensitive)\n",
    "        matches = [col for col in prefix_cols if keyword in col]\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    # Find matching columns\n",
    "    height_col = find_col(\"height\")\n",
    "    storage_col = find_col(\"storage\")\n",
    "    current_col = find_col(\"current\")\n",
    "    last_year_col = find_col(\"lastyear\")\n",
    "\n",
    "    # If we find no relevant columns, return empty\n",
    "    if not any([height_col, storage_col, current_col, last_year_col]):\n",
    "        return [], None\n",
    "\n",
    "    # Build DataFrame\n",
    "    cols = {'date': 'date'}\n",
    "    if height_col: cols[height_col] = 'height_m'\n",
    "    if storage_col: cols[storage_col] = 'storage_ml'\n",
    "    if current_col: cols[current_col] = 'percent_full'\n",
    "    if last_year_col: cols[last_year_col] = 'last_year_percent_full'\n",
    "\n",
    "    col_keys = list(cols.keys())\n",
    "    if 'date' not in col_keys:\n",
    "        col_keys = ['date'] + col_keys\n",
    "    ts = df[col_keys].copy()\n",
    "    # ts['date'] = pd.to_datetime(ts['date']).dt.strftime('%Y-%m-%d')  # ensure datetime\n",
    "    ts.rename(columns=cols, inplace=True)\n",
    "\n",
    "    # Ensure numeric columns are truly numeric\n",
    "    for col in ['height_m', 'storage_ml', 'percent_full', 'last_year_percent_full']:\n",
    "        if col in ts.columns:\n",
    "            ts[col] = pd.to_numeric(ts[col], errors='coerce')\n",
    "\n",
    "    # format nulls\n",
    "    ts = ts.where(pd.notnull(ts), None)\n",
    "\n",
    "    return ts\n",
    "\n",
    "\n",
    "# Create output containers\n",
    "dam_ts_daily = {}\n",
    "dam_ts_monthly = {}\n",
    "dam_ts_yearly = {}\n",
    "\n",
    "for dam_name, prefix in dam_name_mapping.items():\n",
    "    df_ts = build_timeseries(prefix)\n",
    "    if df_ts is None or df_ts.empty:\n",
    "        print('no data set found')\n",
    "        continue\n",
    "\n",
    "    df_ts['date'] = pd.to_datetime(df_ts['date'])\n",
    "\n",
    "    # DAILY\n",
    "    df_ts_sorted = df_ts.sort_values('date')\n",
    "    df_ts_sorted = df_ts_sorted.round(2)\n",
    "    df_ts_sorted['date'] = df_ts_sorted['date'].dt.strftime('%Y-%m-%d')\n",
    "    dam_ts_daily[prefix] = df_ts_sorted.where(pd.notnull(df_ts_sorted), None).to_dict(orient='records')\n",
    "\n",
    "    # MONTHLY\n",
    "    monthly = df_ts.resample('ME', on='date').mean(numeric_only=True).reset_index()\n",
    "    monthly = monthly.round(2)\n",
    "    monthly['date'] = monthly['date'].dt.strftime('%Y-%m')\n",
    "    dam_ts_monthly[prefix] = monthly.where(pd.notnull(monthly), None).to_dict(orient='records')\n",
    "\n",
    "    # YEARLY\n",
    "    yearly = df_ts.resample('YE', on='date').mean(numeric_only=True).reset_index()\n",
    "    yearly = yearly.round(2)\n",
    "    yearly['date'] = yearly['date'].dt.strftime('%Y')\n",
    "    dam_ts_yearly[prefix] = yearly.where(pd.notnull(yearly), None).to_dict(orient='records')\n",
    "\n",
    "\n",
    "# Update GeoJSON properties with current_percentage_full and current_date\n",
    "for i, row in gdf.iterrows():\n",
    "    dam_name = row[\"NAME\"]\n",
    "    prefix = dam_name_mapping.get(dam_name)\n",
    "    if not prefix:\n",
    "        continue\n",
    "\n",
    "    df_ts = build_timeseries(prefix)\n",
    "\n",
    "    # df_ts = pd.DataFrame(ts)\n",
    "    df_ts['date'] = pd.to_datetime(df_ts['date'])\n",
    "    current = df_ts.dropna(subset=['percent_full']) if 'percent_full' in df_ts.columns else df_ts\n",
    "\n",
    "    if not current.empty and 'percent_full' in current.columns:\n",
    "        current_pct = current.sort_values(\"date\").iloc[-1]['percent_full']\n",
    "        current_date = current.sort_values(\"date\").iloc[-1]['date'].strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        current_pct = None\n",
    "        current_date = None\n",
    "\n",
    "    # Update GeoJson\n",
    "    gdf.at[i, 'current_percentage_full'] = current_pct\n",
    "    gdf.at[i, 'current_date'] = current_date\n",
    "\n",
    "    if row[\"geometry\"]:\n",
    "        centroid = row[\"geometry\"].centroid\n",
    "        gdf.at[i, 'centroid'] = Point(centroid.x, centroid.y)\n",
    "    else:\n",
    "        gdf.at[i, 'centroid'] = None\n",
    "\n",
    "# Clean NaNs recursively\n",
    "def clean_nans(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_nans(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_nans(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (np.isnan(v := obj)):\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "# Save Timeseries data\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/dam_levels_daily.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(dam_ts_daily), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/dam_levels_monthly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(dam_ts_monthly), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/dam_levels_yearly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(dam_ts_yearly), f, indent=2)\n",
    "\n",
    "# Save enriched GeoJSON\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "gdf.to_file(\"output/Bulk_Water_Dams_Enriched.geojson\", driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282339e-12cd-469f-88ee-e4322c1f85da",
   "metadata": {},
   "source": [
    "### STEP 2: Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419c3005-73ba-4505-b022-13809028c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_nans(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_nans(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_nans(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (np.isnan(v := obj)):\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "\n",
    "# Define Cape Town coordinates\n",
    "cape_town = Point(-33.9258, 18.4232)\n",
    "\n",
    "# Time range: last 20 years\n",
    "start = datetime(2000, 1, 1)\n",
    "end = datetime(2025, 5, 18)\n",
    "\n",
    "# Fetch daily weather data\n",
    "data = Daily(cape_town, start, end)\n",
    "data = data.fetch()\n",
    "\n",
    "# Filter for average temperature and precipitation\n",
    "df = data[['tavg', 'prcp']].copy()\n",
    "\n",
    "# resample monthly\n",
    "monthly = df.resample('ME').mean()\n",
    "monthly['prcp'] = df['prcp'].resample('ME').sum()\n",
    "\n",
    "# resample yearly\n",
    "yearly = df.resample('YE').mean()\n",
    "yearly['prcp'] = df['prcp'].resample('YE').sum()\n",
    "\n",
    "# Add date columns for export\n",
    "df = df.copy()\n",
    "df = df.sort_index()\n",
    "df['date'] = df.index.strftime('%Y-%m-%d')\n",
    "daily_out = df.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "monthly = monthly.copy()\n",
    "monthly['date'] = monthly.index.strftime('%Y-%m')\n",
    "monthly_out = monthly.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "yearly = yearly.copy()\n",
    "yearly['date'] = yearly.index.strftime('%Y')\n",
    "yearly_out = yearly.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_daily.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(daily_out.to_dict(orient='records')), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_monthly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(monthly_out.to_dict(orient='records')), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_yearly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(yearly_out.to_dict(orient='records')), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdd511-7dbe-4b5f-b9bb-9b09a90855cd",
   "metadata": {},
   "source": [
    "### STEP 3: Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8f1323-db5e-42b2-8fd8-5460f0ba26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "annualPpopulationData = 'data/2025-05-19/Cape-Town-Population-Total-Population-By-Year-2025-05-17-22-32.csv'\n",
    "\n",
    "# Load dam levels CSV\n",
    "df = pd.read_csv(annualPpopulationData)\n",
    "df.rename(columns={'Unnamed: 0': 'year'}, inplace=True)\n",
    "# df['year'] = pd.to_datetime(df['year'])\n",
    "df.columns = ['year', 'population']\n",
    "\n",
    "df = df[['year', 'population']].dropna().sort_values('year')\n",
    "\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_population_yearly.json\", \"w\") as f:\n",
    "    json.dump(df.to_dict(orient='records'), f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
