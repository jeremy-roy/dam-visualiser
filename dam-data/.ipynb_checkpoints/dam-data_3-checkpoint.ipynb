{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b834e-b864-4744-ba5c-0be9d77c9877",
   "metadata": {},
   "source": [
    "# Western Cape Dam Levels\n",
    "Data has been downloaded from City of Cape Town Open Data Portal:  \n",
    "\n",
    "## GIS\n",
    "City of Cape Town Corporate GIS  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::bulk-water-dams-1/explore?location=-33.865920%2C19.071866%2C11.86  \n",
    "<br>\n",
    "Bulk Water dams (Bulk_Water_Dams.geojson):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::bulk-water-dams-1/explore?location=-33.865920%2C19.071866%2C11.86  \n",
    "<br>\n",
    "## Timeseries\n",
    "Dam Levels (Dam_Levels_from_2012.csv):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::dam-levels-from-2012/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Water Consumption (data/Water_consumption.xlsx):  \n",
    "https://odp-cctegis.opendata.arcgis.com/documents/cctegis::water-consumption-1/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Inland Water Quality Monthly Summary Report (Inland_WQ_Summary_Report.pdf):  \n",
    "https://odp-cctegis.opendata.arcgis.com/documents/cctegis::inland-water-quality-monthly-summary-report/about  \n",
    "<br>\n",
    "(Not Useful)  \n",
    "Rainfall Data From 2000 (Rainfall_Data_2000_to_2024.csv):  \n",
    "https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::rainfall-data-from-2000-1/explore  \n",
    "\n",
    "## Weather Data\n",
    "meteostat python package \n",
    "\n",
    "## Poulations data\n",
    "https://www.macrotrends.net/global-metrics/cities/22481/cape-town/population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38fba9f-02a6-4d34-a3df-f0b1d7869532",
   "metadata": {},
   "source": [
    "### STEP 1: Dam Levels Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69b062ec-61a2-4d69-ac6e-f35d39652719",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'centroid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/frame.py:4561\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   4560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4561\u001b[0m     icol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4562\u001b[0m     iindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(index)\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'centroid'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 141\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    140\u001b[0m     centroid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcentroid\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcentroid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [centroid\u001b[38;5;241m.\u001b[39mx, centroid\u001b[38;5;241m.\u001b[39my]\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     gdf\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentroid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexing.py:2586\u001b[0m, in \u001b[0;36m_AtIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   2584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexing.py:2542\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough indexers for scalar access (setting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2542\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/frame.py:4575\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   4573\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[index, col] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   4574\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4575\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   4576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_cache\u001b[38;5;241m.\u001b[39mpop(col, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4578\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidIndexError \u001b[38;5;28;01mas\u001b[39;00m ii_err:\n\u001b[1;32m   4579\u001b[0m     \u001b[38;5;66;03m# GH48729: Seems like you are trying to assign a value to a\u001b[39;00m\n\u001b[1;32m   4580\u001b[0m     \u001b[38;5;66;03m# row when only scalar options are permitted\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexing.py:1890\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key] \u001b[38;5;241m=\u001b[39m infer_fill_value(value)\n\u001b[1;32m   1887\u001b[0m     new_indexer \u001b[38;5;241m=\u001b[39m convert_from_missing_indexer_tuple(\n\u001b[1;32m   1888\u001b[0m         indexer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m   1889\u001b[0m     )\n\u001b[0;32m-> 1890\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;66;03m# reindex the axis\u001b[39;00m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;66;03m# make sure to clear the cache because we are\u001b[39;00m\n\u001b[1;32m   1896\u001b[0m \u001b[38;5;66;03m# just replacing the block manager here\u001b[39;00m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;66;03m# so the object is the same\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1942\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/Documents/dam-visualisations/jupyter-env/lib/python3.9/site-packages/pandas/core/indexing.py:1998\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(info_axis):\n\u001b[1;32m   1994\u001b[0m         \u001b[38;5;66;03m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m         \u001b[38;5;66;03m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[38;5;241m0\u001b[39m]), value[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 1998\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1999\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2001\u001b[0m     )\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m   2004\u001b[0m     \u001b[38;5;66;03m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load dam polygon GeoJSON\n",
    "gdf = gpd.read_file(\"data/2025-05-01/Bulk_Water_Dams.geojson\")\n",
    "\n",
    "# Load dam levels CSV, set date format\n",
    "df = pd.read_csv(\"data/2025-05-19/Dam_Levels_from_2012.csv\", encoding=\"ISO-8859-1\")\n",
    "df['DATE'] = df['DATE'].str.replace('Sept', 'Sep', regex=False)\n",
    "df['DATE'] = pd.to_datetime(df['DATE'], format='%d-%b-%y')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(r\"\\s+\", \"\", regex=True).str.lower()\n",
    "\n",
    "# Mapping from NAME in GeoJSON to CSV prefix (lowercase, no spaces)\n",
    "dam_name_mapping = {\n",
    "    \"Woodhead\": \"woodhead\",\n",
    "    \"Hely-Hutchinson\": \"hely-hutchinson\",\n",
    "    \"Lewis Gay\": \"lewisgay\",\n",
    "    \"Kleinplaats\": \"kleinplaats\",\n",
    "    \"Victoria\": \"victoria\",\n",
    "    \"Alexandra\": \"alexandra\",\n",
    "    \"De Villiers\": \"devilliers\",\n",
    "    \"Steenbras Lower\": \"steenbraslower\",\n",
    "    \"Steenbras Upper\": \"steenbrasupper\",\n",
    "    \"Voëlvlei\": \"voëlvlei\",\n",
    "    \"Wemmershoek\": \"wemmershoek\",\n",
    "    \"Theewaterskloof\": \"theewaterskloof\",\n",
    "    \"Berg River\": \"bergriver\",\n",
    "    \"Land-en-Zeezicht Dam\": \"land-enzeezicht\",\n",
    "    \"Big 5 Total\": \"totalstored-big5\",\n",
    "    \"Big 6 Total\": \"totalstored-big6\"\n",
    "}\n",
    "\n",
    "def build_timeseries(prefix):\n",
    "    # Find all columns related to this dam (that start with the prefix)\n",
    "    prefix_cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "\n",
    "    def find_col(keyword):\n",
    "        # Look for a column that contains the keyword (case-insensitive)\n",
    "        matches = [col for col in prefix_cols if keyword in col]\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    # Find matching columns\n",
    "    height_col = find_col(\"height\")\n",
    "    storage_col = find_col(\"storage\")\n",
    "    current_col = find_col(\"current\")\n",
    "    last_year_col = find_col(\"lastyear\")\n",
    "\n",
    "    # If we find no relevant columns, return empty\n",
    "    if not any([height_col, storage_col, current_col, last_year_col]):\n",
    "        return [], None\n",
    "\n",
    "    # Build DataFrame\n",
    "    cols = {'date': 'date'}\n",
    "    if height_col: cols[height_col] = 'height_m'\n",
    "    if storage_col: cols[storage_col] = 'storage_ml'\n",
    "    if current_col: cols[current_col] = 'percent_full'\n",
    "    if last_year_col: cols[last_year_col] = 'last_year_percent_full'\n",
    "\n",
    "    col_keys = list(cols.keys())\n",
    "    if 'date' not in col_keys:\n",
    "        col_keys = ['date'] + col_keys\n",
    "    ts = df[col_keys].copy()\n",
    "    # ts['date'] = pd.to_datetime(ts['date']).dt.strftime('%Y-%m-%d')  # ensure datetime\n",
    "    ts.rename(columns=cols, inplace=True)\n",
    "\n",
    "    # Ensure numeric columns are truly numeric\n",
    "    for col in ['height_m', 'storage_ml', 'percent_full', 'last_year_percent_full']:\n",
    "        if col in ts.columns:\n",
    "            ts[col] = pd.to_numeric(ts[col], errors='coerce')\n",
    "\n",
    "    # format nulls\n",
    "    ts = ts.where(pd.notnull(ts), None)\n",
    "\n",
    "    return ts\n",
    "\n",
    "\n",
    "# Create output containers\n",
    "dam_ts_daily = {}\n",
    "dam_ts_monthly = {}\n",
    "dam_ts_yearly = {}\n",
    "\n",
    "for dam_name, prefix in dam_name_mapping.items():\n",
    "    df_ts = build_timeseries(prefix)\n",
    "    if not ts:\n",
    "        continue\n",
    "\n",
    "    df_ts['date'] = pd.to_datetime(df_ts['date'])\n",
    "\n",
    "    # DAILY\n",
    "    df_ts_sorted = df_ts.sort_values('date')\n",
    "    df_ts_sorted = df_ts_sorted.round(2)\n",
    "    df_ts_sorted['date'] = df_ts_sorted['date'].dt.strftime('%Y-%m-%d')\n",
    "    dam_ts_daily[prefix] = df_ts_sorted.where(pd.notnull(df_ts_sorted), None).to_dict(orient='records')\n",
    "\n",
    "    # MONTHLY\n",
    "    monthly = df_ts.resample('ME', on='date').mean(numeric_only=True).reset_index()\n",
    "    monthly = monthly.round(2)\n",
    "    monthly['date'] = monthly['date'].dt.strftime('%Y-%m')\n",
    "    dam_ts_monthly[prefix] = monthly.where(pd.notnull(monthly), None).to_dict(orient='records')\n",
    "\n",
    "    # YEARLY\n",
    "    yearly = df_ts.resample('YE', on='date').mean(numeric_only=True).reset_index()\n",
    "    yearly = yearly.round(2)\n",
    "    yearly['date'] = yearly['date'].dt.strftime('%Y')\n",
    "    dam_ts_yearly[prefix] = yearly.where(pd.notnull(yearly), None).to_dict(orient='records')\n",
    "\n",
    "\n",
    "# Update GeoJSON properties with current_percentage_full and current_date\n",
    "for i, row in gdf.iterrows():\n",
    "    dam_name = row[\"NAME\"]\n",
    "    prefix = dam_name_mapping.get(dam_name)\n",
    "    if not prefix:\n",
    "        continue\n",
    "\n",
    "    df_ts = build_timeseries(prefix)\n",
    "\n",
    "    # df_ts = pd.DataFrame(ts)\n",
    "    df_ts['date'] = pd.to_datetime(df_ts['date'])\n",
    "    current = df_ts.dropna(subset=['percent_full']) if 'percent_full' in df_ts.columns else df_ts\n",
    "\n",
    "    if not current.empty and 'percent_full' in current.columns:\n",
    "        current_pct = current.sort_values(\"date\").iloc[-1]['percent_full']\n",
    "        current_date = current.sort_values(\"date\").iloc[-1]['date'].strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        current_pct = None\n",
    "        current_date = None\n",
    "\n",
    "    # Update GeoJson\n",
    "    gdf.at[i, 'current_percentage_full'] = current_pct\n",
    "    gdf.at[i, 'current_date'] = current_date\n",
    "\n",
    "    # Add centroid if geometry exists\n",
    "    if row[\"geometry\"]:\n",
    "        centroid = row[\"geometry\"].centroid\n",
    "        gdf.at[i, 'centroid'] = [centroid.x, centroid.y]\n",
    "    else:\n",
    "        gdf.at[i, 'centroid'] = None\n",
    "\n",
    "# Clean NaNs recursively\n",
    "def clean_nans(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_nans(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_nans(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (np.isnan(v := obj)):\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "# # Save Timeseries data\n",
    "# os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "# with open(\"output/timeseries/dam_levels_daily.json\", \"w\") as f:\n",
    "#     json.dump(clean_nans(dam_ts_daily), f, indent=2)\n",
    "\n",
    "# with open(\"output/timeseries/dam_levels_monthly.json\", \"w\") as f:\n",
    "#     json.dump(clean_nans(dam_ts_monthly), f, indent=2)\n",
    "\n",
    "# with open(\"output/timeseries/dam_levels_yearly.json\", \"w\") as f:\n",
    "#     json.dump(clean_nans(dam_ts_yearly), f, indent=2)\n",
    "\n",
    "# # Save enriched GeoJSON\n",
    "# os.makedirs(\"output\", exist_ok=True)\n",
    "# gdf.to_file(\"output/Bulk_Water_Dams_Enriched.geojson\", driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282339e-12cd-469f-88ee-e4322c1f85da",
   "metadata": {},
   "source": [
    "### STEP 2: Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419c3005-73ba-4505-b022-13809028c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_nans(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_nans(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_nans(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (np.isnan(v := obj)):\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "\n",
    "# Define Cape Town coordinates\n",
    "cape_town = Point(-33.9258, 18.4232)\n",
    "\n",
    "# Time range: last 20 years\n",
    "start = datetime(2000, 1, 1)\n",
    "end = datetime(2025, 5, 18)\n",
    "\n",
    "# Fetch daily weather data\n",
    "data = Daily(cape_town, start, end)\n",
    "data = data.fetch()\n",
    "\n",
    "# Filter for average temperature and precipitation\n",
    "df = data[['tavg', 'prcp']].copy()\n",
    "\n",
    "# resample monthly\n",
    "monthly = df.resample('ME').mean()\n",
    "monthly['prcp'] = df['prcp'].resample('ME').sum()\n",
    "\n",
    "# resample yearly\n",
    "yearly = df.resample('YE').mean()\n",
    "yearly['prcp'] = df['prcp'].resample('YE').sum()\n",
    "\n",
    "# Add date columns for export\n",
    "df = df.copy()\n",
    "df = df.sort_index()\n",
    "df['date'] = df.index.strftime('%Y-%m-%d')\n",
    "daily_out = df.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "monthly = monthly.copy()\n",
    "monthly['date'] = monthly.index.strftime('%Y-%m')\n",
    "monthly_out = monthly.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "yearly = yearly.copy()\n",
    "yearly['date'] = yearly.index.strftime('%Y')\n",
    "yearly_out = yearly.reset_index(drop=True)[['date', 'tavg', 'prcp']]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_daily.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(daily_out.to_dict(orient='records')), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_monthly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(monthly_out.to_dict(orient='records')), f, indent=2)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_rainfall_yearly.json\", \"w\") as f:\n",
    "    json.dump(clean_nans(yearly_out.to_dict(orient='records')), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdd511-7dbe-4b5f-b9bb-9b09a90855cd",
   "metadata": {},
   "source": [
    "### STEP 3: Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8f1323-db5e-42b2-8fd8-5460f0ba26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "annualPpopulationData = 'data/2025-05-19/Cape-Town-Population-Total-Population-By-Year-2025-05-17-22-32.csv'\n",
    "\n",
    "# Load dam levels CSV\n",
    "df = pd.read_csv(annualPpopulationData)\n",
    "df.rename(columns={'Unnamed: 0': 'year'}, inplace=True)\n",
    "# df['year'] = pd.to_datetime(df['year'])\n",
    "df.columns = ['year', 'population']\n",
    "\n",
    "df = df[['year', 'population']].dropna().sort_values('year')\n",
    "\n",
    "os.makedirs(\"output/timeseries\", exist_ok=True)\n",
    "\n",
    "with open(\"output/timeseries/cape_town_population_yearly.json\", \"w\") as f:\n",
    "    json.dump(df.to_dict(orient='records'), f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
